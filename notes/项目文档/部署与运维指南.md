# 部署与运维指南

## 1. 部署概述

本文档详细描述了多功能文件编辑器项目的部署策略、环境配置、运维流程和监控方案。涵盖从开发环境到生产环境的完整部署生命周期，确保系统的稳定性、安全性和可扩展性。

## 2. 部署架构

### 2.1 系统架构图

```
┌─────────────────────────────────────────────────────────────┐
│                        负载均衡层                             │
│                    Nginx / HAProxy                          │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────┴───────────────────────────────────────┐
│                        Web服务层                             │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐          │
│  │   Node.js   │  │   Node.js   │  │   Node.js   │          │
│  │   Instance  │  │   Instance  │  │   Instance  │          │
│  │     #1      │  │     #2      │  │     #3      │          │
│  └─────────────┘  └─────────────┘  └─────────────┘          │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────┴───────────────────────────────────────┐
│                        应用服务层                             │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐          │
│  │  File API   │  │  Auth API   │  │  Admin API  │          │
│  │  Service    │  │  Service    │  │  Service    │          │
│  └─────────────┘  └─────────────┘  └─────────────┘          │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────┴───────────────────────────────────────┐
│                        数据存储层                             │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐          │
│  │   File      │  │   Redis     │  │   MySQL     │          │
│  │  Storage    │  │   Cache     │  │ Database    │          │
│  └─────────────┘  └─────────────┘  └─────────────┘          │
└─────────────────────────────────────────────────────────────┘
```

### 2.2 环境分层

#### 2.2.1 开发环境
```yaml
# 开发环境配置
development:
  frontend:
    host: localhost
    port: 3001
    hot_reload: true
    debug_mode: true
  
  backend:
    host: localhost
    port: 30001
    debug: true
    log_level: debug
  
  database:
    type: sqlite
    path: ./data/dev.db
  
  storage:
    type: local
    path: ./notes
  
  cache:
    enabled: false
```

#### 2.2.2 测试环境
```yaml
# 测试环境配置
testing:
  frontend:
    host: test.example.com
    port: 80
    build_mode: production
  
  backend:
    host: api-test.example.com
    port: 30001
    debug: false
    log_level: info
  
  database:
    type: mysql
    host: mysql-test.internal
    port: 3306
    database: file_editor_test
    username: test_user
    password: test_password
  
  storage:
    type: s3
    bucket: file-editor-test
    region: us-west-2
  
  cache:
    enabled: true
    host: redis-test.internal
    port: 6379
```

#### 2.2.3 生产环境
```yaml
# 生产环境配置
production:
  frontend:
    host: app.example.com
    port: 443
    ssl: true
    build_mode: production
    compression: true
  
  backend:
    host: api.example.com
    port: 443
    ssl: true
    debug: false
    log_level: warn
    cluster_mode: true
    instances: 4
  
  database:
    type: mysql
    host: mysql-prod.internal
    port: 3306
    database: file_editor_prod
    username: prod_user
    password: ${DB_PASSWORD}
    pool_size: 20
    replica:
      host: mysql-replica.internal
      port: 3306
  
  storage:
    type: s3
    bucket: file-editor-prod
    region: us-west-2
    cdn: https://cdn.example.com
  
  cache:
    enabled: true
    host: redis-prod.internal
    port: 6379
    cluster_mode: true
    sentinel:
      hosts:
        - redis-sentinel-1.internal:26379
        - redis-sentinel-2.internal:26379
        - redis-sentinel-3.internal:26379
```

## 3. 部署流程

### 3.1 容器化部署

#### 3.1.1 Dockerfile配置
```dockerfile
# 前端Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/nginx.conf
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

```dockerfile
# 后端Dockerfile
FROM node:18-alpine

WORKDIR /app

# 安装系统依赖
RUN apk add --no-cache \
    python3 \
    make \
    g++ \
    cairo-dev \
    jpeg-dev \
    pango-dev \
    musl-dev \
    giflib-dev \
    pixman-dev \
    pangomm-dev \
    libjpeg-turbo-dev \
    freetype-dev

# 复制package文件
COPY package*.json ./
RUN npm ci --only=production

# 复制源代码
COPY . .

# 构建应用
RUN npm run build

# 创建非root用户
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nodejs -u 1001

# 设置权限
RUN chown -R nodejs:nodejs /app
USER nodejs

EXPOSE 30001
CMD ["node", "server/app.js"]
```

#### 3.1.2 Docker Compose配置
```yaml
# docker-compose.yml
version: '3.8'

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3001:80"
    environment:
      - NODE_ENV=production
    depends_on:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "30001:30001"
    environment:
      - NODE_ENV=production
      - DB_HOST=mysql
      - DB_PASSWORD=${DB_PASSWORD}
      - REDIS_HOST=redis
    volumes:
      - ./notes:/app/notes
      - ./logs:/app/logs
    depends_on:
      - mysql
      - redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:30001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  mysql:
    image: mysql:8.0
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - MYSQL_DATABASE=file_editor
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
    volumes:
      - mysql_data:/var/lib/mysql
      - ./mysql/init:/docker-entrypoint-initdb.d
      - ./mysql/conf:/etc/mysql/conf.d
    ports:
      - "3306:3306"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    ports:
      - "6379:6379"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - frontend
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  mysql_data:
  redis_data:
```

### 3.2 Kubernetes部署

#### 3.2.1 命名空间配置
```yaml
# namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: file-editor
  labels:
    name: file-editor
    environment: production
```

#### 3.2.2 ConfigMap配置
```yaml
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: file-editor-config
  namespace: file-editor
data:
  NODE_ENV: "production"
  LOG_LEVEL: "warn"
  REDIS_HOST: "redis-service"
  DB_HOST: "mysql-service"
  
  nginx.conf: |
    upstream backend {
        server backend-service:30001;
    }
    
    upstream frontend {
        server frontend-service:80;
    }
    
    server {
        listen 80;
        server_name app.example.com;
        
        location / {
            proxy_pass http://frontend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
        
        location /api/ {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
```

#### 3.2.3 Secret配置
```yaml
# secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: file-editor-secrets
  namespace: file-editor
type: Opaque
data:
  DB_PASSWORD: <base64-encoded-password>
  REDIS_PASSWORD: <base64-encoded-password>
  JWT_SECRET: <base64-encoded-secret>
```

#### 3.2.4 部署配置
```yaml
# frontend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend-deployment
  namespace: file-editor
spec:
  replicas: 3
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: frontend
        image: file-editor/frontend:latest
        ports:
        - containerPort: 80
        envFrom:
        - configMapRef:
            name: file-editor-config
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5

---
# backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend-deployment
  namespace: file-editor
spec:
  replicas: 4
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
      - name: backend
        image: file-editor/backend:latest
        ports:
        - containerPort: 30001
        envFrom:
        - configMapRef:
            name: file-editor-config
        - secretRef:
            name: file-editor-secrets
        volumeMounts:
        - name: notes-storage
          mountPath: /app/notes
        - name: logs-storage
          mountPath: /app/logs
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 30001
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 30001
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: notes-storage
        persistentVolumeClaim:
          claimName: notes-pvc
      - name: logs-storage
        persistentVolumeClaim:
          claimName: logs-pvc
```

#### 3.2.5 服务配置
```yaml
# services.yaml
apiVersion: v1
kind: Service
metadata:
  name: frontend-service
  namespace: file-editor
spec:
  selector:
    app: frontend
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
  namespace: file-editor
spec:
  selector:
    app: backend
  ports:
  - protocol: TCP
    port: 30001
    targetPort: 30001
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: mysql-service
  namespace: file-editor
spec:
  selector:
    app: mysql
  ports:
  - protocol: TCP
    port: 3306
    targetPort: 3306
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: redis-service
  namespace: file-editor
spec:
  selector:
    app: redis
  ports:
  - protocol: TCP
    port: 6379
    targetPort: 6379
  type: ClusterIP
```

#### 3.2.6 Ingress配置
```yaml
# ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: file-editor-ingress
  namespace: file-editor
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
spec:
  tls:
  - hosts:
    - app.example.com
    - api.example.com
    secretName: file-editor-tls
  rules:
  - host: app.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend-service
            port:
              number: 80
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: backend-service
            port:
              number: 30001
```

## 4. CI/CD流程

### 4.1 GitLab CI配置

#### 4.1.1 GitLab CI文件
```yaml
# .gitlab-ci.yml
stages:
  - test
  - build
  - deploy-staging
  - deploy-production

variables:
  DOCKER_REGISTRY: registry.example.com
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"

# 测试阶段
test:
  stage: test
  image: node:18-alpine
  services:
    - mysql:8.0
    - redis:7-alpine
  variables:
    MYSQL_ROOT_PASSWORD: test
    MYSQL_DATABASE: test
    MYSQL_USER: test
    MYSQL_PASSWORD: test
  before_script:
    - cd frontend
    - npm ci
    - cd ../backend
    - npm ci
  script:
    - cd ../frontend && npm run test:coverage
    - cd ../backend && npm run test:coverage
    - npm run lint
    - npm run security:audit
  coverage: '/Lines\s*:\s*(\d+\.\d+)%/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: frontend/coverage/cobertura-coverage.xml
    paths:
      - frontend/coverage/
      - backend/coverage/
    expire_in: 1 week

# 构建阶段
build-frontend:
  stage: build
  image: docker:20.10.16
  services:
    - docker:20.10.16-dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - cd frontend
    - docker build -t $DOCKER_REGISTRY/file-editor/frontend:$CI_COMMIT_SHA .
    - docker push $DOCKER_REGISTRY/file-editor/frontend:$CI_COMMIT_SHA
    - docker tag $DOCKER_REGISTRY/file-editor/frontend:$CI_COMMIT_SHA $DOCKER_REGISTRY/file-editor/frontend:latest
    - docker push $DOCKER_REGISTRY/file-editor/frontend:latest
  only:
    - main
    - develop

build-backend:
  stage: build
  image: docker:20.10.16
  services:
    - docker:20.10.16-dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - cd backend
    - docker build -t $DOCKER_REGISTRY/file-editor/backend:$CI_COMMIT_SHA .
    - docker push $DOCKER_REGISTRY/file-editor/backend:$CI_COMMIT_SHA
    - docker tag $DOCKER_REGISTRY/file-editor/backend:$CI_COMMIT_SHA $DOCKER_REGISTRY/file-editor/backend:latest
    - docker push $DOCKER_REGISTRY/file-editor/backend:latest
  only:
    - main
    - develop

# 部署到测试环境
deploy-staging:
  stage: deploy-staging
  image: bitnami/kubectl:latest
  environment:
    name: staging
    url: https://staging.example.com
  before_script:
    - kubectl config use-context staging-cluster
  script:
    - kubectl set image deployment/frontend-deployment frontend=$DOCKER_REGISTRY/file-editor/frontend:$CI_COMMIT_SHA -n file-editor-staging
    - kubectl set image deployment/backend-deployment backend=$DOCKER_REGISTRY/file-editor/backend:$CI_COMMIT_SHA -n file-editor-staging
    - kubectl rollout status deployment/frontend-deployment -n file-editor-staging
    - kubectl rollout status deployment/backend-deployment -n file-editor-staging
  only:
    - develop

# 部署到生产环境
deploy-production:
  stage: deploy-production
  image: bitnami/kubectl:latest
  environment:
    name: production
    url: https://app.example.com
  before_script:
    - kubectl config use-context production-cluster
  script:
    - kubectl set image deployment/frontend-deployment frontend=$DOCKER_REGISTRY/file-editor/frontend:$CI_COMMIT_SHA -n file-editor
    - kubectl set image deployment/backend-deployment backend=$DOCKER_REGISTRY/file-editor/backend:$CI_COMMIT_SHA -n file-editor
    - kubectl rollout status deployment/frontend-deployment -n file-editor
    - kubectl rollout status deployment/backend-deployment -n file-editor
  when: manual
  only:
    - main
```

### 4.2 GitHub Actions配置

#### 4.2.1 GitHub Actions工作流
```yaml
# .github/workflows/deploy.yml
name: Build and Deploy

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      mysql:
        image: mysql:8.0
        env:
          MYSQL_ROOT_PASSWORD: test
          MYSQL_DATABASE: test
        options: >-
          --health-cmd="mysqladmin ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=3
      
      redis:
        image: redis:7
        options: >-
          --health-cmd="redis-cli ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=3

    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
    
    - name: Install dependencies
      run: |
        cd frontend && npm ci
        cd ../backend && npm ci
    
    - name: Run tests
      run: |
        cd frontend && npm run test:coverage
        cd ../backend && npm run test:coverage
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        files: ./frontend/coverage/lcov.info,./backend/coverage/lcov.info

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
    
    strategy:
      matrix:
        component: [frontend, backend]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Log in to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v4
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/${{ matrix.component }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
    
    - name: Build and push Docker image
      uses: docker/build-push-action@v4
      with:
        context: ./${{ matrix.component }}
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    environment: production
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Configure kubectl
      uses: azure/k8s-set-context@v3
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG }}
    
    - name: Deploy to Kubernetes
      run: |
        kubectl set image deployment/frontend-deployment frontend=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/frontend:${{ github.sha }} -n file-editor
        kubectl set image deployment/backend-deployment backend=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/backend:${{ github.sha }} -n file-editor
        kubectl rollout status deployment/frontend-deployment -n file-editor
        kubectl rollout status deployment/backend-deployment -n file-editor
```

## 5. 监控与日志

### 5.1 监控系统

#### 5.1.1 Prometheus配置
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "file_editor_rules.yml"

scrape_configs:
  - job_name: 'file-editor-backend'
    static_configs:
      - targets: ['backend-service:30001']
    metrics_path: '/metrics'
    scrape_interval: 10s

  - job_name: 'file-editor-frontend'
    static_configs:
      - targets: ['frontend-service:80']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'mysql'
    static_configs:
      - targets: ['mysql-exporter:9104']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx-exporter:9113']

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

#### 5.1.2 Grafana仪表板
```json
{
  "dashboard": {
    "title": "File Editor Dashboard",
    "panels": [
      {
        "title": "API Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          }
        ]
      },
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "singlestat",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])",
            "legendFormat": "Error Rate"
          }
        ]
      },
      {
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "process_resident_memory_bytes",
            "legendFormat": "{{instance}}"
          }
        ]
      },
      {
        "title": "CPU Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(process_cpu_seconds_total[5m])",
            "legendFormat": "{{instance}}"
          }
        ]
      }
    ]
  }
}
```

### 5.2 日志管理

#### 5.2.1 ELK Stack配置
```yaml
# elasticsearch.yml
cluster.name: "file-editor-logs"
network.host: 0.0.0.0
discovery.type: single-node
xpack.security.enabled: false
xpack.monitoring.collection.enabled: true

---
# logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][service] == "file-editor" {
    json {
      source => "message"
    }
    
    date {
      match => [ "timestamp", "ISO8601" ]
    }
    
    if [level] == "error" {
      mutate {
        add_tag => [ "error" ]
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "file-editor-%{+YYYY.MM.dd}"
  }
}
```

#### 5.2.2 Filebeat配置
```yaml
# filebeat.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /app/logs/*.log
  fields:
    service: file-editor
    environment: production
  fields_under_root: true
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'
  multiline.negate: true
  multiline.match: after

output.logstash:
  hosts: ["logstash:5044"]

processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_docker_metadata: ~
  - add_kubernetes_metadata: ~
```

### 5.3 告警配置

#### 5.3.1 Alertmanager配置
```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'smtp.example.com:587'
  smtp_from: 'alerts@example.com'

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'
  routes:
  - match:
      severity: critical
    receiver: 'critical-alerts'
  - match:
      severity: warning
    receiver: 'warning-alerts'

receivers:
- name: 'web.hook'
  webhook_configs:
  - url: 'http://127.0.0.1:5001/'

- name: 'critical-alerts'
  email_configs:
  - to: 'ops-team@example.com'
    subject: '[CRITICAL] File Editor Alert'
    body: |
      {{ range .Alerts }}
      Alert: {{ .Annotations.summary }}
      Description: {{ .Annotations.description }}
      {{ end }}
  slack_configs:
  - api_url: 'YOUR_SLACK_WEBHOOK_URL'
    channel: '#alerts'
    title: 'Critical Alert'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

- name: 'warning-alerts'
  email_configs:
  - to: 'dev-team@example.com'
    subject: '[WARNING] File Editor Alert'
    body: |
      {{ range .Alerts }}
      Alert: {{ .Annotations.summary }}
      Description: {{ .Annotations.description }}
      {{ end }}
```

#### 5.3.2 告警规则
```yaml
# file_editor_rules.yml
groups:
- name: file_editor_alerts
  rules:
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value | humanizePercentage }} for the last 5 minutes"

  - alert: HighResponseTime
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High response time detected"
      description: "95th percentile response time is {{ $value }}s"

  - alert: HighMemoryUsage
    expr: process_resident_memory_bytes / 1024 / 1024 > 500
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage detected"
      description: "Memory usage is {{ $value }}MB"

  - alert: ServiceDown
    expr: up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Service is down"
      description: "{{ $labels.instance }} has been down for more than 1 minute"

  - alert: DiskSpaceUsage
    expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes > 0.8
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Disk space usage high"
      description: "Disk usage is {{ $value | humanizePercentage }}"
```

## 6. 备份与恢复

### 6.1 备份策略

#### 6.1.1 数据库备份
```bash
#!/bin/bash
# backup_mysql.sh

# 配置变量
BACKUP_DIR="/backups/mysql"
DATE=$(date +%Y%m%d_%H%M%S)
DB_NAME="file_editor"
DB_USER="backup_user"
DB_PASSWORD="${MYSQL_PASSWORD}"
RETENTION_DAYS=30

# 创建备份目录
mkdir -p $BACKUP_DIR

# 执行备份
mysqldump -h mysql-service -u $DB_USER -p$DB_PASSWORD \
  --single-transaction \
  --routines \
  --triggers \
  --all-databases \
  | gzip > $BACKUP_DIR/backup_$DATE.sql.gz

# 验证备份
if [ $? -eq 0 ]; then
  echo "Backup completed successfully: backup_$DATE.sql.gz"
  
  # 删除过期备份
  find $BACKUP_DIR -name "backup_*.sql.gz" -mtime +$RETENTION_DAYS -delete
  
  # 上传到云存储
  aws s3 cp $BACKUP_DIR/backup_$DATE.sql.gz s3://file-editor-backups/mysql/
else
  echo "Backup failed"
  exit 1
fi
```

#### 6.1.2 文件备份
```bash
#!/bin/bash
# backup_files.sh

# 配置变量
BACKUP_DIR="/backups/files"
SOURCE_DIR="/app/notes"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30

# 创建备份目录
mkdir -p $BACKUP_DIR

# 执行增量备份
rsync -av --delete \
  --link-dest=$BACKUP_DIR/latest \
  $SOURCE_DIR/ $BACKUP_DIR/backup_$DATE/

# 更新最新链接
rm -f $BACKUP_DIR/latest
ln -s backup_$DATE $BACKUP_DIR/latest

# 压缩备份
tar -czf $BACKUP_DIR/files_backup_$DATE.tar.gz -C $BACKUP_DIR backup_$DATE

# 删除未压缩的备份
rm -rf $BACKUP_DIR/backup_$DATE

# 上传到云存储
aws s3 cp $BACKUP_DIR/files_backup_$DATE.tar.gz s3://file-editor-backups/files/

# 清理过期备份
find $BACKUP_DIR -name "files_backup_*.tar.gz" -mtime +$RETENTION_DAYS -delete
```

### 6.2 自动化备份

#### 6.2.1 Kubernetes CronJob
```yaml
# backup-cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: mysql-backup
  namespace: file-editor
spec:
  schedule: "0 2 * * *"  # 每天凌晨2点
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: mysql-backup
            image: mysql:8.0
            command:
            - /bin/bash
            - -c
            - |
              mysqldump -h mysql-service -u $MYSQL_USER -p$MYSQL_PASSWORD \
                --single-transaction \
                --routines \
                --triggers \
                $MYSQL_DATABASE \
                | gzip > /backup/backup_$(date +%Y%m%d_%H%M%S).sql.gz
              
              aws s3 cp /backup/ s3://file-editor-backups/mysql/ --recursive
            env:
            - name: MYSQL_USER
              valueFrom:
                secretKeyRef:
                  name: file-editor-secrets
                  key: DB_USER
            - name: MYSQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: file-editor-secrets
                  key: DB_PASSWORD
            - name: MYSQL_DATABASE
              value: "file_editor"
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc
          restartPolicy: OnFailure
```

### 6.3 恢复流程

#### 6.3.1 数据库恢复
```bash
#!/bin/bash
# restore_mysql.sh

# 配置变量
BACKUP_FILE=$1
DB_NAME="file_editor"
DB_USER="root"
DB_PASSWORD="${MYSQL_ROOT_PASSWORD}"

if [ -z "$BACKUP_FILE" ]; then
  echo "Usage: $0 <backup_file>"
  exit 1
fi

# 解压备份文件
gunzip -c $BACKUP_FILE > /tmp/restore.sql

# 执行恢复
mysql -h mysql-service -u $DB_USER -p$DB_PASSWORD < /tmp/restore.sql

if [ $? -eq 0 ]; then
  echo "Database restored successfully"
  rm -f /tmp/restore.sql
else
  echo "Database restore failed"
  exit 1
fi
```

## 7. 安全配置

### 7.1 网络安全

#### 7.1.1 防火墙配置
```bash
#!/bin/bash
# firewall_setup.sh

# 清除现有规则
iptables -F
iptables -X
iptables -t nat -F
iptables -t nat -X

# 设置默认策略
iptables -P INPUT DROP
iptables -P FORWARD DROP
iptables -P OUTPUT ACCEPT

# 允许本地回环
iptables -A INPUT -i lo -j ACCEPT

# 允许已建立的连接
iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT

# 允许SSH
iptables -A INPUT -p tcp --dport 22 -j ACCEPT

# 允许HTTP/HTTPS
iptables -A INPUT -p tcp --dport 80 -j ACCEPT
iptables -A INPUT -p tcp --dport 443 -j ACCEPT

# 允许内部服务通信
iptables -A INPUT -s 10.0.0.0/8 -j ACCEPT
iptables -A INPUT -s 172.16.0.0/12 -j ACCEPT
iptables -A INPUT -s 192.168.0.0/16 -j ACCEPT

# 保存规则
iptables-save > /etc/iptables/rules.v4
```

#### 7.1.2 SSL/TLS配置
```nginx
# nginx SSL配置
server {
    listen 443 ssl http2;
    server_name app.example.com;
    
    # SSL证书
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    
    # SSL配置
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;
    
    # 安全头
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    add_header X-Frame-Options DENY always;
    add_header X-Content-Type-Options nosniff always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;
    
    # 应用配置
    location / {
        proxy_pass http://frontend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

### 7.2 应用安全

#### 7.2.1 安全中间件
```javascript
// 安全中间件配置
const helmet = require('helmet')
const rateLimit = require('express-rate-limit')
const cors = require('cors')

// 基础安全配置
app.use(helmet({
  contentSecurityPolicy: {
    directives: {
      defaultSrc: ["'self'"],
      styleSrc: ["'self'", "'unsafe-inline'", "https://fonts.googleapis.com"],
      fontSrc: ["'self'", "https://fonts.gstatic.com"],
      scriptSrc: ["'self'"],
      imgSrc: ["'self'", "data:", "https:"]
    }
  },
  hsts: {
    maxAge: 31536000,
    includeSubDomains: true,
    preload: true
  }
}))

// CORS配置
app.use(cors({
  origin: process.env.ALLOWED_ORIGINS?.split(',') || ['http://localhost:3001'],
  credentials: true,
  optionsSuccessStatus: 200
}))

// 速率限制
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15分钟
  max: 100, // 限制每个IP 15分钟内最多100个请求
  message: 'Too many requests from this IP',
  standardHeaders: true,
  legacyHeaders: false
})

app.use('/api/', limiter)

// 文件上传限制
const uploadLimiter = rateLimit({
  windowMs: 60 * 1000, // 1分钟
  max: 10, // 限制每个IP 1分钟内最多10次上传
  message: 'Too many upload requests'
})

app.use('/api/upload', uploadLimiter)
```

## 8. 性能优化

### 8.1 应用性能优化

#### 8.1.1 缓存策略
```javascript
// Redis缓存配置
const redis = require('redis')
const client = redis.createClient({
  host: process.env.REDIS_HOST,
  port: process.env.REDIS_PORT,
  password: process.env.REDIS_PASSWORD,
  retry_strategy: (options) => {
    if (options.error && options.error.code === 'ECONNREFUSED') {
      return new Error('Redis server refused connection')
    }
    if (options.total_retry_time > 1000 * 60 * 60) {
      return new Error('Retry time exhausted')
    }
    if (options.attempt > 10) {
      return undefined
    }
    return Math.min(options.attempt * 100, 3000)
  }
})

// 缓存中间件
const cache = (duration = 300) => {
  return async (req, res, next) => {
    const key = `cache:${req.originalUrl}`
    
    try {
      const cached = await client.get(key)
      if (cached) {
        return res.json(JSON.parse(cached))
      }
      
      // 重写res.json以缓存响应
      const originalJson = res.json
      res.json = function(data) {
        client.setex(key, duration, JSON.stringify(data))
        return originalJson.call(this, data)
      }
      
      next()
    } catch (error) {
      next()
    }
  }
}

// 使用缓存
app.get('/api/files', cache(600), getFileTree)
app.get('/api/file', cache(300), getFileContent)
```

#### 8.1.2 数据库优化
```javascript
// 数据库连接池配置
const mysql = require('mysql2/promise')

const pool = mysql.createPool({
  host: process.env.DB_HOST,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD,
  database: process.env.DB_NAME,
  waitForConnections: true,
  connectionLimit: 20,
  queueLimit: 0,
  acquireTimeout: 60000,
  timeout: 60000,
  reconnect: true,
  charset: 'utf8mb4'
})

// 查询优化
const optimizedQuery = async (sql, params = []) => {
  const start = Date.now()
  
  try {
    const [rows] = await pool.execute(sql, params)
    const duration = Date.now() - start
    
    // 记录慢查询
    if (duration > 1000) {
      console.warn(`Slow query detected: ${duration}ms`, { sql, params })
    }
    
    return rows
  } catch (error) {
    console.error('Database query failed:', error)
    throw error
  }
}

// 索引优化建议
const indexSuggestions = [
  'CREATE INDEX idx_files_path ON files(path)',
  'CREATE INDEX idx_files_created_at ON files(created_at)',
  'CREATE INDEX idx_users_email ON users(email)',
  'CREATE INDEX idx_sessions_user_id ON sessions(user_id)'
]
```

### 8.2 前端性能优化

#### 8.2.1 构建优化
```javascript
// vite.config.js
import { defineConfig } from 'vite'
import vue from '@vitejs/plugin-vue'
import { resolve } from 'path'

export default defineConfig({
  plugins: [vue()],
  
  build: {
    target: 'es2015',
    outDir: 'dist',
    assetsDir: 'assets',
    sourcemap: false,
    minify: 'terser',
    
    // 代码分割
    rollupOptions: {
      output: {
        manualChunks: {
          vendor: ['vue', 'vue-router', 'pinia'],
          ui: ['element-plus'],
          editor: ['@monaco-editor/loader'],
          utils: ['lodash', 'dayjs']
        }
      }
    },
    
    // 压缩配置
    terserOptions: {
      compress: {
        drop_console: true,
        drop_debugger: true
      }
    },
    
    // 资源内联阈值
    assetsInlineLimit: 4096
  },
  
  // 开发服务器配置
  server: {
    host: '0.0.0.0',
    port: 3001,
    proxy: {
      '/api': {
        target: 'http://localhost:30001',
        changeOrigin: true
      }
    }
  },
  
  // 路径别名
  resolve: {
    alias: {
      '@': resolve(__dirname, 'src')
    }
  }
})
```

## 9. 故障排除

### 9.1 常见问题

#### 9.1.1 服务启动失败
```bash
# 检查服务状态
kubectl get pods -n file-editor
kubectl describe pod <pod-name> -n file-editor

# 查看日志
kubectl logs <pod-name> -n file-editor --tail=100

# 进入容器调试
kubectl exec -it <pod-name> -n file-editor -- /bin/bash

# 检查资源使用
kubectl top pods -n file-editor
kubectl top nodes
```

#### 9.1.2 数据库连接问题
```bash
# 测试数据库连接
mysql -h mysql-service -u root -p -e "SHOW DATABASES;"

# 检查数据库状态
kubectl exec -it mysql-pod -n file-editor -- mysql -u root -p -e "SHOW PROCESSLIST;"

# 检查连接池状态
kubectl logs backend-pod -n file-editor | grep -i "connection"
```

#### 9.1.3 性能问题诊断
```bash
# 检查CPU和内存使用
kubectl exec -it backend-pod -n file-editor -- top
kubectl exec -it backend-pod -n file-editor -- ps aux

# 检查网络连接
kubectl exec -it backend-pod -n file-editor -- netstat -tulpn

# 检查磁盘空间
kubectl exec -it backend-pod -n file-editor -- df -h
```

### 9.2 应急响应

#### 9.2.1 服务恢复流程
```bash
#!/bin/bash
# emergency_recovery.sh

echo "Starting emergency recovery..."

# 1. 检查集群状态
kubectl get nodes
kubectl get pods -n file-editor

# 2. 重启故障服务
kubectl rollout restart deployment/backend-deployment -n file-editor
kubectl rollout restart deployment/frontend-deployment -n file-editor

# 3. 等待服务就绪
kubectl rollout status deployment/backend-deployment -n file-editor --timeout=300s
kubectl rollout status deployment/frontend-deployment -n file-editor --timeout=300s

# 4. 验证服务
curl -f http://app.example.com/health || echo "Frontend health check failed"
curl -f http://api.example.com/health || echo "Backend health check failed"

# 5. 检查日志
kubectl logs -l app=backend -n file-editor --tail=50 | grep -i error
kubectl logs -l app=frontend -n file-editor --tail=50 | grep -i error

echo "Emergency recovery completed"
```

## 10. 总结

本部署与运维指南为多功能文件编辑器项目提供了全面的部署和运维指导，涵盖了从环境配置到监控告警的完整流程。通过标准化的部署流程、完善的监控体系和应急响应机制，确保系统的稳定运行和快速故障恢复。

### 10.1 核心要点
1. **容器化部署**: 使用Docker和Kubernetes实现标准化部署
2. **CI/CD自动化**: 通过GitLab CI或GitHub Actions实现持续集成和部署
3. **监控告警**: 建立完善的监控体系和告警机制
4. **备份恢复**: 制定完整的数据备份和恢复策略
5. **安全防护**: 实施多层次的安全防护措施
6. **性能优化**: 持续优化系统性能和用户体验

### 10.2 最佳实践
1. **基础设施即代码**: 使用YAML/JSON定义所有基础设施
2. **自动化运维**: 尽可能自动化所有运维操作
3. **监控驱动**: 基于监控数据进行运维决策
4. **安全优先**: 在所有环节考虑安全因素
5. **文档完善**: 保持文档的及时更新和完善

通过严格执行本指南中的规范和流程，运维团队可以确保系统的高可用性、高性能和安全性，为用户提供稳定可靠的服务。
